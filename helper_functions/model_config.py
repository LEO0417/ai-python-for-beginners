# -*- coding: utf-8 -*-
"""
æ¨¡å‹é…ç½®ç®¡ç†æ¨¡å—
Model Configuration Management Module

æä¾›æ™ºèƒ½çš„ollamaæ¨¡å‹é…ç½®å’Œç®¡ç†åŠŸèƒ½
Provides intelligent ollama model configuration and management
"""

import os
import json
import subprocess

def get_default_model():
    """
    æ™ºèƒ½è·å–é»˜è®¤æ¨¡å‹ï¼ŒæŒ‰ä¼˜å…ˆçº§é¡ºåºï¼š
    1. ç¯å¢ƒå˜é‡ OLLAMA_MODEL
    2. è¯¾ç¨‹çº§é…ç½®æ–‡ä»¶ {lesson}/ollama_config.json
    3. å…¨å±€é…ç½®æ–‡ä»¶ ollama_config.json
    4. è‡ªåŠ¨æ£€æµ‹ç¬¬ä¸€ä¸ªå¯ç”¨æ¨¡å‹
    5. å›é€€åˆ°é¢„è®¾é»˜è®¤å€¼
    
    Smart default model detection with priority order:
    1. Environment variable OLLAMA_MODEL
    2. Lesson-level config file {lesson}/ollama_config.json
    3. Global config file ollama_config.json
    4. Auto-detect first available model
    5. Fallback to preset default
    
    Returns:
        str: æ¨¡å‹åç§° / Model name
    """
    
    # 1. æ£€æŸ¥ç¯å¢ƒå˜é‡ / Check environment variable
    env_model = os.getenv('OLLAMA_MODEL')
    if env_model:
        return env_model
    
    # 2. æ£€æŸ¥è¯¾ç¨‹çº§é…ç½®æ–‡ä»¶ / Check lesson-level config file
    lesson_config_model = _get_lesson_config_model()
    if lesson_config_model:
        return lesson_config_model
    
    # 3. æ£€æŸ¥å…¨å±€é…ç½®æ–‡ä»¶ / Check global config file
    global_config_model = _get_global_config_model()
    if global_config_model:
        return global_config_model
    
    # 4. è‡ªåŠ¨æ£€æµ‹å¯ç”¨æ¨¡å‹ / Auto-detect available models
    available_model = _get_first_available_model()
    if available_model:
        return available_model
    
    # 5. å›é€€åˆ°é»˜è®¤å€¼ / Fallback to default
    return "gemma3n:latest"

def _get_lesson_config_model():
    """ä»è¯¾ç¨‹çº§é…ç½®æ–‡ä»¶è¯»å–æ¨¡å‹è®¾ç½® / Read model setting from lesson-level config file"""
    try:
        # å°è¯•æ‰¾åˆ°å½“å‰è¯¾ç¨‹çš„é…ç½®æ–‡ä»¶
        # Try to find current lesson's config file
        current_dir = os.getcwd()
        lesson_config_file = os.path.join(current_dir, 'ollama_config.json')
        
        if os.path.exists(lesson_config_file):
            with open(lesson_config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
                return config.get('default_model')
    except Exception:
        pass
    return None

def _get_global_config_model():
    """ä»å…¨å±€é…ç½®æ–‡ä»¶è¯»å–æ¨¡å‹è®¾ç½® / Read model setting from global config file"""
    try:
        # æŸ¥æ‰¾é¡¹ç›®æ ¹ç›®å½•çš„é…ç½®æ–‡ä»¶
        # Look for config file in project root
        project_root = _get_project_root()
        global_config_file = os.path.join(project_root, 'ollama_config.json')
        
        if os.path.exists(global_config_file):
            with open(global_config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
                return config.get('default_model')
    except Exception:
        pass
    return None

def _get_first_available_model():
    """è‡ªåŠ¨æ£€æµ‹ç¬¬ä¸€ä¸ªå¯ç”¨çš„ollamaæ¨¡å‹ / Auto-detect first available ollama model"""
    try:
        result = subprocess.run(['ollama', 'list'], 
                              capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            lines = result.stdout.strip().split('\n')
            # è·³è¿‡æ ‡é¢˜è¡Œï¼Œè·å–ç¬¬ä¸€ä¸ªæ¨¡å‹
            # Skip header line, get first model
            for line in lines[1:]:
                if line.strip():
                    model_name = line.split()[0]  # è·å–æ¨¡å‹åç§°
                    if model_name and ':' in model_name:
                        return model_name
    except Exception:
        pass
    return None

def _get_project_root():
    """è·å–é¡¹ç›®æ ¹ç›®å½• / Get project root directory"""
    current_dir = os.path.dirname(os.path.abspath(__file__))
    return os.path.dirname(current_dir)

def set_default_model(model_name, scope='global'):
    """
    è®¾ç½®é»˜è®¤æ¨¡å‹åˆ°é…ç½®æ–‡ä»¶
    Set default model to config file
    
    Args:
        model_name (str): æ¨¡å‹åç§° / Model name
        scope (str): é…ç½®èŒƒå›´ 'global' æˆ– 'lesson' / Configuration scope 'global' or 'lesson'
    """
    try:
        if scope == 'lesson':
            # è®¾ç½®è¯¾ç¨‹çº§é…ç½® / Set lesson-level config
            config_file = os.path.join(os.getcwd(), 'ollama_config.json')
        else:
            # è®¾ç½®å…¨å±€é…ç½® / Set global config
            project_root = _get_project_root()
            config_file = os.path.join(project_root, 'ollama_config.json')
        
        config = {}
        
        # è¯»å–ç°æœ‰é…ç½® / Read existing config
        if os.path.exists(config_file):
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)
            except Exception:
                pass
        
        # æ›´æ–°é…ç½® / Update config
        config['default_model'] = model_name
        
        # ä¿å­˜é…ç½® / Save config
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        
        scope_text = "å…¨å±€" if scope == 'global' else "è¯¾ç¨‹çº§"
        print(f"âœ… {scope_text}é»˜è®¤æ¨¡å‹å·²è®¾ç½®ä¸º: {model_name}")
        print(f"âœ… {scope.title()} default model set to: {model_name}")
        
    except Exception as e:
        print(f"âŒ ä¿å­˜é…ç½®å¤±è´¥ / Failed to save config: {e}")

def get_available_models():
    """
    è·å–æ‰€æœ‰å¯ç”¨çš„ollamaæ¨¡å‹åˆ—è¡¨
    Get list of all available ollama models
    
    Returns:
        list: å¯ç”¨æ¨¡å‹åˆ—è¡¨ / List of available models
    """
    try:
        result = subprocess.run(['ollama', 'list'], 
                              capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            lines = result.stdout.strip().split('\n')
            models = []
            for line in lines[1:]:  # è·³è¿‡æ ‡é¢˜è¡Œ
                if line.strip():
                    model_info = line.split()
                    if model_info and ':' in model_info[0]:
                        models.append(model_info[0])
            return models
    except Exception:
        pass
    return []

def show_model_info():
    """æ˜¾ç¤ºå½“å‰æ¨¡å‹é…ç½®ä¿¡æ¯ / Show current model configuration info"""
    print("ğŸ” å½“å‰æ¨¡å‹é…ç½®ä¿¡æ¯ / Current Model Configuration Info")
    print("=" * 50)
    
    # æ˜¾ç¤ºå½“å‰ä½¿ç”¨çš„æ¨¡å‹
    current_model = get_default_model()
    print(f"ğŸ“ å½“å‰ä½¿ç”¨æ¨¡å‹ / Current model: {current_model}")
    
    # æ˜¾ç¤ºé…ç½®æ¥æº
    env_model = os.getenv('OLLAMA_MODEL')
    if env_model:
        print(f"ğŸŒ ç¯å¢ƒå˜é‡ / Environment variable: {env_model}")
    
    lesson_model = _get_lesson_config_model()
    if lesson_model:
        print(f"ğŸ“ è¯¾ç¨‹çº§é…ç½® / Lesson config: {lesson_model}")
    
    global_model = _get_global_config_model()
    if global_model:
        print(f"ğŸŒ å…¨å±€é…ç½® / Global config: {global_model}")
    
    # æ˜¾ç¤ºå¯ç”¨æ¨¡å‹
    available_models = get_available_models()
    if available_models:
        print(f"ğŸ“‹ å¯ç”¨æ¨¡å‹ / Available models: {', '.join(available_models)}")
    else:
        print("âš ï¸  æœªæ£€æµ‹åˆ°å¯ç”¨æ¨¡å‹ / No available models detected")
    
    print("=" * 50)
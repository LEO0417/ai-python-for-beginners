# -*- coding: utf-8 -*-
"""
AI PythonåŒè¯­è¯¾ç¨‹ - å…±äº«å·¥å…·åŒ…
AI Python Bilingual Course - Shared Utilities Package

è¿™ä¸ªåŒ…æä¾›äº†æ‰€æœ‰è¯¾ç¨‹å…±ç”¨çš„è¾…åŠ©å‡½æ•°å’Œå·¥å…·
This package provides shared helper functions and utilities for all lessons
"""

import os
import sys

# è‡ªåŠ¨æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
# Automatically add project root to Python path
def _setup_path():
    """è®¾ç½®Pythonè·¯å¾„ä»¥æ”¯æŒä»ä»»æ„ä½ç½®å¯¼å…¥ / Setup Python path for imports from any location"""
    current_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(current_dir)
    if project_root not in sys.path:
        sys.path.insert(0, project_root)

_setup_path()

# å¯¼å…¥æ‰€æœ‰å¸¸ç”¨å‡½æ•° / Import all common functions
try:
    from .model_config import get_default_model, set_default_model
    from .llm_utils import print_llm_response, get_llm_response
    from .common_utils import *
    
    # æä¾›å‘åå…¼å®¹çš„æ¥å£ / Provide backward compatibility interface
    __all__ = [
        'get_default_model',
        'set_default_model',
        'print_llm_response',
        'get_llm_response',
        'read_journal'
    ]
    
except ImportError as e:
    # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œæä¾›å‹å¥½çš„é”™è¯¯ä¿¡æ¯
    # If import fails, provide friendly error message
    print(f"âš ï¸  å¯¼å…¥å…±äº«å·¥å…·åŒ…æ—¶å‡ºç°é—®é¢˜ / Issue importing shared utilities: {e}")
    print("è¯·ç¡®ä¿æ‰€æœ‰æ¨¡å—æ–‡ä»¶éƒ½å·²æ­£ç¡®åˆ›å»º / Please ensure all module files are properly created")

# ç‰ˆæœ¬ä¿¡æ¯ / Version information
__version__ = "1.0.0"
__author__ = "AI Python Bilingual Course Team"

# ä½¿ç”¨è¯´æ˜ / Usage instructions
def show_usage():
    """æ˜¾ç¤ºä½¿ç”¨è¯´æ˜ / Show usage instructions"""
    print("""
ğŸš€ AI PythonåŒè¯­è¯¾ç¨‹ - å…±äº«å·¥å…·åŒ…ä½¿ç”¨è¯´æ˜
ğŸš€ AI Python Bilingual Course - Shared Utilities Usage

åŸºæœ¬ä½¿ç”¨ / Basic Usage:
    from shared_utils import print_llm_response, get_llm_response
    from shared_utils import get_default_model, set_default_model

æ¨¡å‹é…ç½® / Model Configuration:
    # æ£€æŸ¥å½“å‰æ¨¡å‹ / Check current model
    print(get_default_model())
    
    # è®¾ç½®é»˜è®¤æ¨¡å‹ / Set default model
    set_default_model("llama2:latest")

LLMè°ƒç”¨ / LLM Calls:
    # æ‰“å°å“åº” / Print response
    print_llm_response("Hello, how are you?")
    
    # è·å–å“åº” / Get response
    response = get_llm_response("What is Python?")

ç¯å¢ƒå˜é‡é…ç½® / Environment Variable Configuration:
    export OLLAMA_MODEL="your-model:latest"

æ›´å¤šä¿¡æ¯è¯·æŸ¥çœ‹é¡¹ç›®æ–‡æ¡£ / For more information, see project documentation
    """)

# ä¾¿æ·å‡½æ•° / Convenience functions
def version():
    """è¿”å›ç‰ˆæœ¬ä¿¡æ¯ / Return version information"""
    return __version__

def help():
    """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯ / Show help information"""
    show_usage()
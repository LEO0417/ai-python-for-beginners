#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¨¡å‹é…ç½®æµ‹è¯•è„šæœ¬ / Model Configuration Test Script

è¿™ä¸ªè„šæœ¬å¸®åŠ©ä½ æµ‹è¯•æ™ºèƒ½æ¨¡å‹é…ç½®æ˜¯å¦æ­£å¸¸å·¥ä½œ
This script helps you test if the smart model configuration is working properly
"""

import os
import sys
import subprocess

def test_ollama_installation():
    """æµ‹è¯•ollamaæ˜¯å¦å·²å®‰è£… / Test if ollama is installed"""
    print("ğŸ” æ£€æŸ¥ollamaå®‰è£…çŠ¶æ€ / Checking ollama installation...")
    try:
        result = subprocess.run(['which', 'ollama'], capture_output=True, text=True)
        if result.returncode == 0:
            print("âœ… ollamaå·²å®‰è£… / ollama is installed")
            return True
        else:
            print("âŒ ollamaæœªå®‰è£… / ollama is not installed")
            print("è¯·è®¿é—® https://ollama.ai ä¸‹è½½å®‰è£… / Please visit https://ollama.ai to download and install")
            return False
    except Exception as e:
        print(f"âŒ æ£€æŸ¥ollamaæ—¶å‡ºé”™ / Error checking ollama: {e}")
        return False

def test_available_models():
    """æµ‹è¯•å¯ç”¨çš„æ¨¡å‹ / Test available models"""
    print("\nğŸ“‹ æ£€æŸ¥å¯ç”¨æ¨¡å‹ / Checking available models...")
    try:
        result = subprocess.run(['ollama', 'list'], capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            lines = result.stdout.strip().split('\n')
            if len(lines) > 1:
                print("âœ… å‘ç°ä»¥ä¸‹æ¨¡å‹ / Found the following models:")
                for line in lines[1:]:
                    if line.strip():
                        model_info = line.split()
                        if model_info:
                            print(f"   - {model_info[0]}")
                return lines[1:]
            else:
                print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ¨¡å‹ / No models found")
                print("è¯·è¿è¡Œ 'ollama pull gemma3n:latest' ä¸‹è½½æ¨¡å‹ / Please run 'ollama pull gemma3n:latest' to download a model")
                return []
        else:
            print("âŒ æ— æ³•è·å–æ¨¡å‹åˆ—è¡¨ / Cannot get model list")
            return []
    except Exception as e:
        print(f"âŒ æ£€æŸ¥æ¨¡å‹æ—¶å‡ºé”™ / Error checking models: {e}")
        return []

def test_environment_variable():
    """æµ‹è¯•ç¯å¢ƒå˜é‡é…ç½® / Test environment variable configuration"""
    print("\nğŸŒ æ£€æŸ¥ç¯å¢ƒå˜é‡é…ç½® / Checking environment variable configuration...")
    env_model = os.getenv('OLLAMA_MODEL')
    if env_model:
        print(f"âœ… å‘ç°ç¯å¢ƒå˜é‡ OLLAMA_MODEL: {env_model}")
        print(f"âœ… Found environment variable OLLAMA_MODEL: {env_model}")
        return env_model
    else:
        print("â„¹ï¸  æœªè®¾ç½®ç¯å¢ƒå˜é‡ OLLAMA_MODEL / Environment variable OLLAMA_MODEL not set")
        print("   å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼è®¾ç½® / You can set it with:")
        print("   export OLLAMA_MODEL='your-model:latest'")
        return None

def test_helper_functions():
    """æµ‹è¯•helper_functionsçš„æ™ºèƒ½é…ç½® / Test smart configuration in helper_functions"""
    print("\nğŸ§ª æµ‹è¯•helper_functionsæ¨¡å— / Testing helper_functions module...")
    
    try:
        # æµ‹è¯•å¯¼å…¥helper_functionsæ¨¡å—
        # Test importing helper_functions modules
        from helper_functions import get_default_model, set_default_model
        from helper_functions.model_config import show_model_info, get_available_models
        
        print("   âœ… helper_functionsæ¨¡å—å¯¼å…¥æˆåŠŸ / helper_functions modules imported successfully")
        
        # æµ‹è¯•get_default_modelå‡½æ•°
        # Test get_default_model function
        model = get_default_model()
        print(f"   âœ… é»˜è®¤æ¨¡å‹ / Default model: {model}")
        
        # æµ‹è¯•è·å–å¯ç”¨æ¨¡å‹
        # Test getting available models
        available_models = get_available_models()
        if available_models:
            print(f"   âœ… å¯ç”¨æ¨¡å‹ / Available models: {', '.join(available_models)}")
        else:
            print("   âš ï¸  æœªæ£€æµ‹åˆ°å¯ç”¨æ¨¡å‹ / No available models detected")
        
        # æ˜¾ç¤ºè¯¦ç»†é…ç½®ä¿¡æ¯
        # Show detailed configuration info
        print("\nğŸ“‹ è¯¦ç»†é…ç½®ä¿¡æ¯ / Detailed Configuration Info:")
        show_model_info()
        
    except Exception as e:
        print(f"   âŒ æµ‹è¯•å¤±è´¥ / Test failed: {e}")

def test_model_response():
    """æµ‹è¯•æ¨¡å‹å“åº” / Test model response"""
    print("\nğŸ¤– æµ‹è¯•æ¨¡å‹å“åº” / Testing model response...")
    
    # ä½¿ç”¨helper_functionsæ¨¡å—æµ‹è¯•
    # Test using helper_functions module
    try:
        from helper_functions import get_llm_response
        from helper_functions.llm_utils import test_llm_connection
        
        print("   å‘é€æµ‹è¯•æç¤ºè¯ / Sending test prompt...")
        response = get_llm_response("Hello, please respond with 'Test successful'")
        
        if "test successful" in response.lower():
            print("   âœ… æ¨¡å‹å“åº”æµ‹è¯•æˆåŠŸ / Model response test successful")
        else:
            print("   âš ï¸  æ”¶åˆ°å“åº”ä½†å¯èƒ½æ˜¯å¤‡ç”¨å“åº” / Received response but might be fallback")
            print(f"   å“åº”å†…å®¹ / Response: {response[:100]}...")
        
        # æµ‹è¯•è¿æ¥çŠ¶æ€
        # Test connection status
        print("   æµ‹è¯•LLMè¿æ¥çŠ¶æ€ / Testing LLM connection status...")
        is_connected = test_llm_connection()
        if is_connected:
            print("   âœ… LLMè¿æ¥æ­£å¸¸ / LLM connection is working")
        else:
            print("   âš ï¸  LLMè¿æ¥å¯èƒ½æœ‰é—®é¢˜ï¼Œä½¿ç”¨å¤‡ç”¨å“åº” / LLM connection might have issues, using fallback")
        
    except Exception as e:
        print(f"   âŒ æ¨¡å‹å“åº”æµ‹è¯•å¤±è´¥ / Model response test failed: {e}")

def main():
    """ä¸»æµ‹è¯•å‡½æ•° / Main test function"""
    print("ğŸš€ AI PythonåŒè¯­è¯¾ç¨‹ - æ¨¡å‹é…ç½®æµ‹è¯•")
    print("ğŸš€ AI Python Bilingual Course - Model Configuration Test")
    print("=" * 60)
    
    # 1. æµ‹è¯•ollamaå®‰è£…
    if not test_ollama_installation():
        return
    
    # 2. æµ‹è¯•å¯ç”¨æ¨¡å‹
    models = test_available_models()
    if not models:
        return
    
    # 3. æµ‹è¯•ç¯å¢ƒå˜é‡
    test_environment_variable()
    
    # 4. æµ‹è¯•helper_functionsæ¨¡å—
    test_helper_functions()
    
    # 5. æµ‹è¯•æ¨¡å‹å“åº”
    test_model_response()
    
    print("\n" + "=" * 60)
    print("ğŸ‰ æµ‹è¯•å®Œæˆ / Testing completed!")
    print("\nğŸ’¡ ä½¿ç”¨å»ºè®® / Usage suggestions:")
    print("1. è®¾ç½®ç¯å¢ƒå˜é‡: export OLLAMA_MODEL='your-model:latest'")
    print("2. æˆ–åœ¨notebookä¸­ä½¿ç”¨: set_default_model('your-model:latest')")
    print("3. æˆ–è®©ç³»ç»Ÿè‡ªåŠ¨æ£€æµ‹ç¬¬ä¸€ä¸ªå¯ç”¨æ¨¡å‹")
    print("\n1. Set environment variable: export OLLAMA_MODEL='your-model:latest'")
    print("2. Or use in notebook: set_default_model('your-model:latest')")
    print("3. Or let system auto-detect first available model")

if __name__ == "__main__":
    main()